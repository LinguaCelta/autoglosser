\documentclass[a4paper,10pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{url}
\usepackage{graphicx}
\usepackage{appendix}
\usepackage{array}
\usepackage{tabularx}
\usepackage[labelfont=bf,textfont=it]{caption}

\setlength{\parindent}{0in}  % no paragraph indents
\setlength{\parskip}{2ex}  % put a linespace between paragraphs

\renewcommand{\rmdefault}{phv}

%opening
\title{\textbf{Autoglossing CHAT files with the Bangor autoglosser}}
\author{Kevin Donnelly\thanks{kevin@dotmon.com}}
\date{28 May 2010}

\begin{document}

\maketitle

\begin{abstract}
This manual explains how to use the Bangor autoglosser to provide glosses for  CLAN\footnote{http://childes.psy.cmu.edu/clan} \textit{.cha} files.  One beneficial side-effect of this process is that the files are stored in a PostgreSQL\footnote{http://www.postgresql.org} database, and this allows them to be used as input into the R statistical package\footnote{http://www.r-project.org} for detailed corpus-related queries.
\end{abstract}


\section{Introduction}
\label{sec:intro}

In the context of CLAN chat files, ``glossing'' means generating an additional tier containing part-of-speech tags.  This autoglosser generates the gloss tier automatically from a POS-tagged dictionary.  The software has been tested on Welsh and Spanish, and could be easily extended to handle any language, provided that you have available:
\begin{itemize}
\item a digital dictionary for that language, and
\item a basic Constraint Grammar\footnote{http://beta.visl.sdu.dk/constraint\_grammar.html} to disambiguate homonyms in the language.
\end{itemize}
If you do not already have access to such resources, you will have to create them - some suggestions on this are given in later sections. 

The Bangor autoglosser is licensed under version 3 of the GPL,\footnote{http://www.gnu.org/licenses/gpl.html}, and was originally developed for use with \textit{\textbf{Siarad}}, the GPLed corpus of Welsh conversations assembled by the ESRC Centre for Research on Bilingualism in Theory and Practice,\footnote{http://bilingualism.bangor.ac.uk} at the University of Wales, Bangor.  The software has been built and tested on GNU/Linux, but it is likely to run also on legacy platforms like Microsoft Windows or Apple Mac OS X.


\section{Installation requirements}
\label{sec:requirements}

Your machine will need to have Apache2, PHP5, PostgreSQL, and (optionally) Git already installed.  The Appendix gives a summary of the relevant commands for Ubuntu 9.10, and suggests how to configure your machine to use these applications effectively -- note that this is only a suggestion, and other approaches are possible.


\section{Overview}
\label{sec:overview}

The stages in the autoglossing pipeline are:
\begin{enumerate}
\item Prepare the file by removing the headers and joining any broken lines (Section \ref{sec:prepare}).
\item Import the file into a table (Section \ref{sec:pipeline} - filename\_cgutterances).
\item Remove non-word markup from the speech tier, and import the individual utterances into a table (filename\_cgwords).
\item Look up each word in a language-specific dictionary to get a cohort of possible lemmas it could derive from, with appropriate part-of-speech tags.
\item Apply a language-specific constraint grammar to each cohort to remove inappropriate entries (i.e. to disambiguate the cohort).
\item Import the disambiguated entries into a table (filename\_cgfinished).
\item Combine information from the three tables to create a new text file where the original speech tier has a new gloss tier.
\end{enumerate}


\section{Prepare the file}
\label{sec:prepare}

These steps are done manually, but can be automated later.  Remove the header lines and paste them to \textbf{outputs/\$filename.header}.  Remove the \textbf{@End} line from the end of the file.  Rename the file to \textbf{\$filename\_headerless}.  Run: \\
\verb|dos2unix inputs/$filename_headerless|\\
Replace filenames in \textbf{utils/sed\_joinlines} and run:\\
\verb|utils/sed_joinlines|\\
This will deal with Microsoft Windows endlines by ensuring that all lines of the text are joined up, and not split over several lines.


\section{Put a file through the pipeline}
\label{sec:pipeline}

File: do\_autogloss.php
Output tables: \$filename\_cgutterances, \$filename\_cgwords, \$filename\_cgfinished
Output file: 

This is the base file which calls all the other components.  This means that you can run a single command on a file as prepared in Section \ref{sec:prepare}, and the glossed file will be produced automatically within a few minutes.  If you have already glossed your file, but want to import it into a database for statistical or other analysis, it is easiest to run the first two commands, cgimport.php (Section \ref{sec:import}) and rewrite\_utterances.php (Section \ref{sec:rewrite}) manually.

From a terminal, navigate to the location of the autoglosser, and enter:
\begin{center}
\texttt{php do\_autogloss.php /path/to/mychafile.cha}                                                     \end{center}
adjusting the path as required for your setup, for instance: 
\begin{center}
\texttt{php do\_autogloss.php inputs/Patagonia1.cha}                                                     \end{center}
The file extensions currently catered for are \textbf{.cha} or \textbf{.txt}, but more can be added by editing the \textbf{get\_filename()} function in \textbf{includes/fns.php}.

The extension is removed, and the name is lowercased, to be used as the \textbf{\$filename} prefix for all tables and files created during the autogloss or import process.  In the above example, the resultant filename would be \textbf{patagonia1}.  The tables that will be created at each stage of the process are given shorthand names: \textbf{\$utterances} for the table \textit{\$filename\_cgutterances}, \textbf{\$words} for the table \textit{\$filename\_cgwords}, and \textbf{\$cgfinished} for the table \textit{\$filename\_cgfinished}.  This allows the names of the tables to be changed easily, should you wish to to so.


\section{Import the file}
\label{sec:import}

\begin{itemize}
\item File: \textbf{cgimport.php}, also calling \textbf{create\_cgutterances.php}
\item Function: Opens the chat file and imports it into the table \textbf{\$filename\_utterances}.
\item Output tables: \textbf{\$filename\_cgutterances}
\item Output file: none                 
\end{itemize}

We call the file create\_cgutterances.php to drop (using the drop\_table() function in includes/fns.php) any existing filename\_utterances table, and recreates it.  The table will hold the segmented chafile.
*** Can change column names here to deal with gloss issue above.  Maybe need to add indexes?  Any benefits in adding another column which holds the complete speech tier, ie without splitting it up?  This would simplify rebuilding.  Need to change the table name from "welsh", so that other languages can be used.  Also need to add a column for the autogloss, so that it can co-exist with any manual gloss.

We add the sourcefile as a column just in case it might be useful in doing queries.  In cases where this is not available in the sound data, we use \$filename generated earlier. *** Perhaps best to generalise this, and use it even with Siarad. *** sample\_id and line\_num may not be needed.

Read in the speech tier, beginning with *.  Split off the sound data.

Read in the glosses, beginning with \%gls.  This may not exist in all files, and is likely not to in files that you are going to autogloss.  Remove non-morphological strings that shouldn't be there (eg x, xx, xxx).
*** Again, this should maybe be abstracted into a function, which could be added to as necessary.  As noted above, perhaps change the column name to mygloss, or manual, or something, so that we have a clear run for the autogloss.

Read in the English interpretation, beginning with \%eng.  Again, this may not exist in all files.
*** Need to find a way of handling any tier, eg \%pho, \%mor, etc.   

Read in comments, beginning with @Comment.  
*** Comments are not well-handled -- we assume only one.  We either need to concat, as with the CG output, or write to another table linked to this one, using utterance\_id as the key.  The latter would mean two tables, and might be less easy to comprehend.

Output is fed to screen as we go through this process.
*** Also write it to a file?


\section{create\_cgwords.php}
\label{sec:words}

This drops any existing \$words table and recreates it.  The table will hold the words from the utterance segmentation.
*** Again, consider adding indexes.  Again, change the welsh column name.  We add sourcefile for tracking purposes, but glossloc is probably no longer necessary, since under the new system it will be the same as location, unless the person doing the glossing has made an error.


\section{rewrite\_utterances.php}
\label{sec:rewrite}

Lifts the utterances out of the \$utterances table and cleans them of any non-word items, eg markers, indicators, etc.  This is in contrast to the previous system, where we tried to retain these.
*** Is there an argument for retaining backtracking markers by appending them to the previous word?  This might help in disambiguation, though it might also slow down the import a good bit.  Add / to the allowed characters, and then replace space between word and / with an underscore?

The cleaning is done using the clean\_utterances() function, which can of course be extended.  Note that the order of the items in the function is significant - the main line removes anything that is not a letter or a few other things, so this has to be run after lines that remove items contained in square brackets.  Also note that if you are using language tags containing \& (the current CLAN recommendation), each of these has to be moved out of the way first, and then moved back again, because otherwise the lines getting rid of things like \&=laugh will affect them too: you will get party@scy instead of party@s:cy\&en.

The original and cleaned utterances are written to a file (\$utterances.txt) for checking purposes.

The speech tier is segmented at a wordspace, and written into the \$words table.  Note that the current language identification is based on the Siarad @ tag -- this will need to be changed if working on other files.
*** Would it be possible to abstract this into a function, so that different tagging systems could be called with a switch?

Any manual glosses are also written into the table.
*** At present there is a check on whether they exist, but this may have no effect - needs to be tested.


\section{write\_cohorts.php}
\label{sec:cohorts}

It would be sensible to allow this and the next file, apply\_cg.php, to be callable standalone, because they need to be run multiple times when developing the constraint grammar.
*** Add code that will handle arguments to the file, so that the \$words tablename can be given directly.  Unfortunately, this will not handle the function and dbconfig lines, so we need to duplicate those here, rather than relying on the ones in do\_autogloss.php.

This lifts out all the surface words in the \$words table and looks them up in the dictionaries.  Then it writes the surface word and it's "cohort" of possible lemmas into a file in the CG format.  See the tutorial on CG for more details.

The dictionary id of each word is also printed, to make it easier to make changes to the dictionary.

Which dictionary to use is based on the langid in the \$words table, so this needs to be adjusted here.
*** Perhaps use global variables to set language tags?  Would also need to apply to dictionary table names.

In each case, if the word is unknown, it is given the UNK tag, but if it begins with a capital, it is given the NAME tag.

Output goes to screen, and also to a file, filename\_cg.txt.
*** Review this name.


\section{apply\_cg.php}
\label{sec:applycg}

This runs vislcg3 on the filename\_cg.txt produced by the previous component, using the specified grammar.
*** Again, this could be set somewhere as a variable, or handled as an argument to the file.  On the other hand, having it in the file, at least during development, makes more sense.

The disambiguated output is written to a file, filename\_cg\_applied.txt.


\section{write\_cgfinished.php}
\label{sec:cgfinished}

The script create\_cgfinished.php drops the table filename\_cgfinished and recreates it.

Then it reads the disambiguated cohort file into this table.  In cases where CG has been unable to reduce the cohort to one entry, glosses are concatenated, and separated by a slash.

It currently outputs a file, cgout.txt, but this is not very useful, since it shows concatenated glosses on separate lines.


\section{write\_cgautogloss.php}
\label{sec:autoglossed}

Currently, this is the last step in the autogloss procedure.  

This collects information from the three tables generated, and writes out a file, filename\_autoglossed.txt, giving the original utterance and its glossed equivalent.  If manual glosses exist, they will be written out too.
*** Need to include code to select this based on whether the manual gloss column is filled.

Note that this file is currently NOT a chafile - it is for checking purposes only.  This script needs to be extended to write out the chafile itself.  This would then need to be tested to ensure it is fully compatible with CLAN.


\section{Further work}
\label{sec:further}

The header details of the chafile are ignored by the import.  In fact, they need to be brought in to a separate table (in which case, having a separate table for comments would not be so bad).  Alternatively, they could be written out to a separate header file, and rejoined as part of the final write -- possibly better since it is simpler, and we are already generating a small thicket of working files anyway.





\newpage
\appendix
\renewcommand{\appendixpagename}{Appendix:\\
Configuring Ubuntu 9.10}
\appendixpage

REVISE: If we are not using a web interface, the info on setting up Apache is not required.  Need to decide on CLI and/or web ...

These instructions should also work on Ubuntu 10.04. In either case, they assume a properly-working desktop with network access.

\section{Install relevant software}

Install Apache (webserver), PHP5 (scripting system), and PostgreSQL (database), phpPgAdmin (browser interface to PostgreSQL), and (optionally) Git (versioning system) and pgAdminIII (desktop interface to PostgreSQL):

\texttt{sudo apt-get install git-core, apache2, apache2-utils, libapache2-mod-php5, php5, php5-cli, php-pear, php5-xcache, php5-pgsql, postgresql, phppgadmin, pgadmin3}

\section{Configure Apache}

\subsection{Configure a virtual host}

\texttt{sudo nano /etc/apache2/sites-available/autoglosser}

Place the following in the file:

\begin{verbatim}
<VirtualHost *:80>
ServerName autoglosser
DocumentRoot /srv/www/autoglosser/public_html/
ErrorLog /srv/www/autoglosser/logs/error.log
CustomLog /srv/www/autoglosser/logs/access.log combined
</VirtualHost>
\end{verbatim}

\subsection{Tell the PC about the new virtual host}

\texttt{sudo nano /etc/hosts}

Add the following line:

\texttt{127.0.0.1	autoglosser}

\subsection{Enable the site and restart Apache}

\texttt{sudo a2ensite autoglosser}

\texttt{sudo /etc/init.d/apache2 restart}

\subsection{Give your normal user access to the \texttt{/srv} directory}

\texttt{sudo chown -R myuser.myuser /srv}

\subsection{Create a directory structure for the virtual host you set up earlier}

\texttt{mkdir -p /srv/www/autoglosser/public\_html}
\texttt{mkdir /srv/www/autoglosser/logs}

\subsection{Create a front-page for the virtual host}
\label{subsec:create-front-page}

\texttt{cd /srv/www/autoglosser/public\_html}

\texttt{nano index.html}

Enter the following:

\begin{verbatim}
<html>
<head>
<title>Autoglosser</title>
</head>
<body>
Front page for autoglosser virtual host.
</body>
</html>
\end{verbatim}

If you now enter \textbf{autoglosser} in the address bar of your browser you should see a page reading \textit{Front page for autoglosser virtual host}.

\section{Configure PHP}

Check the configuration of the \textbf{php.ini} file:

\texttt{sudo /etc/php5/apache2/php.ini}

Set the following parameters as given:

\begin{verbatim}
max_execution_time = 300
memory_limit = 64M
register_globals = Off
magic_quotes_gpc = Off
magic_quotes_runtime = Off
safe_mode = Off.
\end{verbatim}

; UNIX: "/path1:/path2"
include\_path = ".:/home/kevin/autoglosser/includes"


Restart Apache:

\texttt{sudo /etc/init.d/apache2 restart}

\section{Configure PostgreSQL}

\subsection{Set PostgreSQL to use passwords}

\texttt{sudo nano /etc/postgresql/8.4/main/pg\_hba.conf}

Change the line:

\texttt{local   all	all	ident}

to:

\texttt{local   all	all	md5}

\subsection{Create a database user}
\label{subsec:create-db-user}

\texttt{sudo -i}

\texttt{su - postgresql}

\texttt{createuser -P mypguser}

Enter a password (twice), and enter \textbf{y} at the superuser question.

Enter \textbf{exit} twice to return to your normal (desktop) user.

You will have to use the username/password you have just entered to replace the default \textit{kevin/kevindbs} near the top of the \texttt{.php} scripts in the download.

\section{Download the autoglosser}

In a working directory of your choice, run:\\
\texttt{git clone http://thinkopen.co.uk/git/autoglosser}\\
The files will be downloaded into a \textit{autoglosser} folder in your working directory.

If you have chosen not to install Git, you can instead download the files by going to \textbf{http://thinkopen.co.uk/git/}, clicking on \textbf{autoglosser}, then on \textbf{tree}, and finally on \textbf{snapshot}.  This will download a tarball containing the files.  Uncompress this to create a \texttt{autoglosser} folder in your working directory.

Copy all the files in the \texttt{segmenter} folder to your new web directory at \texttt{\url{/srv/www/segmenter/public_html}}.  Delete the \textbf{index.html} file you created earlier at \ref{subsec:create-front-page}.

\section{Initialise the database}

\subsection{Create the database}

Go the the \texttt{dbs} folder and create a new database:

\texttt{createdb -U mypguser autoglosser}

using the PostgreSQL user you created earlier at \ref{subsec:create-db-user}.  Enter your PostgreSQL password when prompted.

\subsection{Import the tables}

[FIX: This section may not be necessary, since the autoglosser creates the tables on the fly.]

Log in to psql as your user:

\texttt{psql -U mypguser autoglosser}

At the \verb|autoglosser=#| prompt, enter:

\verb|\i table1.sql|

\verb|\i table2.sql|

Enter \verb|\q| to exit \textbf{psql}.

\subsection{Configure the database connection}

Open a text editor, and replace the username and password in the file \textbf{autoglosser/config.php} with the PostgreSQL username and password you created earlier at \ref{subsec:create-db-user}.

[FIX: All these files need to have \textbf{siarad} changed to \textbf{autoglosser}.]

Move the configuration details out of the web tree:

\texttt{sudo mv autoglosser /opt}

\section{Test access}

Open a web browser, and enter \textbf{autoglosser} on the location line.  You should see the front page of the autoglosser.

[FIX: Perhaps not required here - see above.]

If this does not work, contact me at \textbf{kevin@dotmon.com}.

\section{Ongoing database administration?}

To administer PostgreSQL, it is easiest to use a frontend.  You can use pgAdminIII\footnote{http://whatever}, a desktop interface, or (preferably) phpPgAdmin\footnote{http://whatever}, a browser-based interface.  Open a browser and enter \textit{localhost/phppgadmin} on the location bar.  Enter your PostgreSQL username and password, and you should see a list of databases in the left-hand panel - since this is a new install, there are only two: the postgres system database, and autoglosser, the one you have just created.  Click on autoglosser, and then on Schemas, and then on Tables.  There are no tables available yet in the autoglosser database, because you have not created any - the import process will create 4 tables for each file you import. 


\newpage


\begin{table}
\newcommand{\mc}[3]{\multicolumn{#1}{#2}{#3}}
\begin{tabularx}{\textwidth}{>{\hsize=0.5\hsize}X>{\hsize=1.5\hsize}X>{\hsize=0.5\hsize}X>{\hsize=1.5\hsize}X} 
\mc{2}{l}{\textbf{Tenses, moods, aspects}} & \mc{2}{l}{\textbf{Verbal extensions}} \\
\hline\noalign{\smallskip}
\textit{comp} & completive \textbf{-sha-, -isha-, -kwisha-} & \textit{assoc} & associative extension \textbf{\mbox{-an-}} \\ 
\textit{conc} & concessional \textbf{-nga-} & \textit{caus} & causative extension \textbf{-iz-, -ez-, -ish-, -esh-, -y-} \\ 
\textit{cond} & conditional \textbf{-nge-} & \textit{cont} & continuative extension \textbf{-t-} \\ 
\textit{cons} & consecutive \textbf{-ka-} & \textit{conv} & conversive extension \textbf{-u-, -o-} \\ 
\textit{curr} & current present \textbf{-na-} & \textit{inc} & inceptive extension \textbf{-p-} \\ 
\textit{fut} & future \textbf{-ta-} & \textit{pass} & passive extension \textbf{-w-} \\ 
\textit{hab} & habitual \textbf{hu-} & \textit{pos} & positional extension \textbf{-m-} \\ 
\textit{hypo} & hypothetical \textbf{-japo-} & \textit{prep} & prepositional extension \textbf{\mbox{-i-}, -e-} \\ 
\textit{imp} & imperative \textbf{-e} & \textit{stat} & stative extension \textbf{-ik-, \mbox{-ek-}} \\ 
\textit{gen} & general present \textbf{-a-} &  &  \\ 
\textit{part} & participial \textbf{-ki-} &  &  \\ 
\textit{past} & past \textbf{-li-} &  &  \\ 
\textit{perf} & perfective \textbf{-me-} &  &  \\ 
\textit{subj} & subjunctive \textbf{-e} &  &  \\ 
\textit{supp} & suppositional \textbf{-ngali-} & & 
\end{tabularx}
\caption{Tense and extension tags}
\label{table:verbtags}
\end{table}


\end{document}