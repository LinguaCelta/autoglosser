\documentclass[a4paper,10pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{url}
\usepackage{graphicx}
\usepackage{appendix}
\usepackage{array}
\usepackage{tabularx}
\usepackage[labelfont=bf,textfont=it]{caption}

\setlength{\parindent}{0in}  % no paragraph indents
\setlength{\parskip}{2ex}  % put a linespace between paragraphs

\renewcommand{\rmdefault}{phv}

%opening
\title{\textbf{Autoglossing CHAT files with the Bangor autoglosser}}
\author{Kevin Donnelly\thanks{kevin@dotmon.com}}
\date{28 May 2010}

\begin{document}

\maketitle

\begin{abstract}
This manual explains how to use the Bangor autoglosser to provide glosses for  CLAN\footnote{http://childes.psy.cmu.edu/clan} \textit{.cha} files.  One beneficial side-effect of this process is that the files are stored in a PostgreSQL\footnote{http://www.postgresql.org} database, and this allows them to be used as input into the R statistical package\footnote{http://www.r-project.org} for detailed corpus-related queries.
\end{abstract}

\section{General}

This autoglosser, which is licensed under version 3 of the GPL,\footnote{http://www.gnu.org/licenses/gpl.html} was originally developed for use with Siarad, the GPLed corpus of Welsh conversations assembled by the University of Bangor's Centre for Research on Bilingualism in Theory and Practice,\footnote{http://bilingualism.bangor.ac.uk} but they should be useable in other contexts.  The autoglosser has been built and tested on GNU/Linux, but it is likely to run also on legacy platforms like Microsoft Windows or Apple Mac OS X.

\section{Requirements}

Your machine will need to have Apache2, PHP5, PostgreSQL, and (optionally) Git already installed.  The Appendix gives a summary of the relevant commands for Ubuntu 9.10, and suggests how to configure your machine to use these applications effectively -- note that this is only a suggestion, and other approaches are possible.

To use the autoglosser, you will need digital dictionaries for the languages you are interested in, and a basic Constraint Grammar\footnote{http://beta.visl.sdu.dk/constraint\_grammar.html} to disambiguate homonyms in those languages.  If you do not already have access to such resources, you will have to create them - some suggestions on this are given in later sections.   Once your system is configured, and your support resources are ready, all you need to do is put the CHAT file you want to autogloss in the \textit{inputs} dir, open a terminal, and run \textbf{php do\_autogloss.php}.

\section{do\_autogloss.php}

This is the base file which calls the other components.  This can be truncated to produce a file that only does imports (eg if you have already glossed your file).  
*** Need to think about whether we do a sample file like this.  And also about the naming of the glosses column - perhaps assume autoglossing and keep gloss for that column, with mygloss for manual glosses.  Need to find a way of writing all the output into a log - at present, opening a file in the script and writing to it doesn't work.
*** May need to review filenames, tablenames, etc.  Create folder for each file, to hold byproduct files? 

Currently, the chafile is hardwired into the script, but it can be handled via an argument to a CLI script, or via a text-box on a webpage.  CLI is probably preferable.
*** Use these to allow subsets of the components to be selected?

It strips the extension .cha, and lowercases the name, to be used as the prefix for all tables and files created during the autogloss or import process.  Two variables are created that are used in the other components: \$utterances (referring to the table filename\_cgutterances) and \$words (referring to the table filename\_cgwords).


\section{create\_cgutterances.php}

This drops any existing \$utterances file (using the drop\_table() function) and recreates it.  The table will hold the segmented chafile.
*** Can change column names here to deal with gloss issue above.  Maybe need to add indexes?  Any benefits in adding another column which holds the complete speech tier, ie without splitting it up?  This would simplify rebuilding.  Need to change the table name from "welsh", so that other languages can be used.  Also need to add a column for the autogloss, so that it can co-exist with any manual gloss.

We add the sourcefile as a column just in case it might be useful in doing queries.  In cases where this is not available in the sound data, we should use \$filename generated earlier.
*** sample\_id and line\_num may not be needed.


\section{cgimport.php}

Opens the chafile given earlier, and imports it into the table \$utterances.  This file could be tidied up a good bit.
*** This was built to do Siarad, and we may need to do different flavours, even within projects.  With the Patagonia files, for instance, the sound bullet holds only the duration; in Siarad it holds the string snd, and the name of the file.
*** We need to include a joinline routine first, to deal with Microsoft Windows endlines.  Sed should be OK for this.

First do some punctuation and error correction.  These may need to be extended for other files.
*** This could perhaps go into a function? 

Read in the speech tier, beginning with *.  Split off the sound data.
*** This will not work in cases where snd is not used to preface this.  Perhaps need to use the NAK character as the split-point.

Read in the glosses, beginning with \%gls.  This may not exist in all files, and is likely not to in files that you are going to autogloss.  Remove non-morphological strings that shouldn't be there (eg x, xx, xxx).
*** Again, this should maybe be abstracted into a function, which could be added to as necessary.  As noted above, perhaps change the column name to mygloss, or manual, or something, so that we have a clear run for the autogloss.

Read in the English interpretation, beginning with \%eng.  Again, this may not exist in all files.
*** Need to find a way of handling any tier, eg \%pho, \%mor, etc.   

Read in comments, beginning with @Comment.  
*** Comments are not well-handled -- we assume only one.  We either need to concat, as with the CG output, or write to another table linked to this one, using utterance\_id as the key.  The latter would mean two tables, and might be less easy to comprehend.

Output is fed to screen as we go through this process.
*** Also write it to a file?


\section{create\_cgwords.php}

This drops any existing \$words table and recreates it.  The table will hold the words from the utterance segmentation.
*** Again, consider adding indexes.  Again, change the welsh column name.  We add sourcefile for tracking purposes, but glossloc is probably no longer necessary, since under the new system it will be the same as location, unless the person doing the glossing has made an error.


\section{rewrite\_utterances.php}

Lifts the utterances out of the \$utterances table and cleans them of any non-word items, eg markers, indicators, etc.  This is in contrast to the previous system, where we tried to retain these.
*** Is there an argument for retaining backtracking markers by appending them to the previous word?  This might help in disambiguation, though it might also slow down the import a good bit.  Add / to the allowed characters, and then replace space between word and / with an underscore?

The cleaning is done using the clean\_utterances() function, which can of course be extended.  Note that the order of the items in the function is significant - the main line removes anything that is not a letter or a few other things, so this has to be run after lines that remove items contained in square brackets.

The original and cleaned utterances are written to a file (\$utterances.txt) for checking purposes.

The speech tier is segmented at a wordspace, and written into the \$words table.  Note that the current language identification is based on the Siarad @ tag -- this will need to be changed if working on other files.
*** Would it be possible to abstract this into a function, so that different tagging systems could be called with a switch?

Any manual glosses are also written into the table.
*** At present there is a check on whether they exist, but this may have no effect - needs to be tested.


===At this point the current pipeline stops, and we need to integrate subsequent files into it.===


\section{write\_cohorts.php}

It would be sensible to allow this and the next file, apply\_cg.php, to be callable standalone, because they need to be run multiple times when developing the constraint grammar.
*** Add code that will handle arguments to the file, so that the \$words tablename can be given directly.  Unfortunately, this will not handle the function and dbconfig lines, so we need to duplicate those here, rather than relying on the ones in do\_autogloss.php.

This lifts out all the surface words in the \$words table and looks them up in the dictionaries.  Then it writes the surface word and it's "cohort" of possible lemmas into a file in the CG format.  See the tutorial on CG for more details.

The dictionary id of each word is also printed, to make it easier to make changes to the dictionary.

Which dictionary to use is based on the langid in the \$words table, so this needs to be adjusted here.
*** Perhaps use global variables to set language tags?  Would also need to apply to dictionary table names.

In each case, if the word is unknown, it is given the UNK tag, but if it begins with a capital, it is given the NAME tag.

Output goes to screen, and also to a file, filename\_cg.txt.
*** Review this name.


\section{apply\_cg.php}

This runs vislcg3 on the filename\_cg.txt produced by the previous component, using the specified grammar.
*** Again, this could be set somewhere as a variable, or handled as an argument to the file.  On the other hand, having it in the file, at least during development, makes more sense.

The disambiguated output is written to a file, filename\_cg\_applied.txt.


\section{create\_cgfinished.php}

This drops the table filename\_cgfinished and recreates it.
*** Put this into a separate file, like the other table-creation components above.

Then it reads the disambiguated cohort file into this table.  In cases where CG has been unable to reduce the cohort to one entry, glosses are concatenated, and separated by a slash.

It currently outputs a file, cgout.txt, but this is not very useful, since it shows concatenated glosses on separate lines.


\section{write\_cgautogloss.php}

Currently, this is the last step in the autogloss procedure.  

This collects information from the three tables generated, and writes out a file, filename\_autoglossed.txt, giving the original utterance and its glossed equivalent.  If manual glosses exist, they will be written out too.
*** Need to include code to select this based on whether the manual gloss column is filled.

Note that this file is NOT a chafile - it is for checking purposes only.  This script needs to be extended to write out the chafile itself.  This would then need to be tested to ensure it is fully compatible with CLAN.


\section{Further work}

The header details of the chafile are ignored by the import.  In fact, they need to be brought in to a separate table (in which case, having a separate table for comments would not be so bad).  Alternatively, they could be written out to a separate header file, and rejoined as part of the final write -- possibly better since it is simpler, and we are already generating a small thicket of working files anyway.





\newpage
\appendix
\renewcommand{\appendixpagename}{Appendix:\\
Configuring Ubuntu 9.10}
\appendixpage

REVISE: If we are not using a web interface, the info on setting up Apache is not required.  Need to decide on CLI and/or web ...

These instructions should also work on Ubuntu 10.04. In either case, they assume a properly-working desktop with network access.

\section{Install relevant software}

Install Apache (webserver), PHP5 (scripting system), and PostgreSQL (database), phpPgAdmin (browser interface to PostgreSQL), and (optionally) Git (versioning system) and pgAdminIII (desktop interface to PostgreSQL):

\texttt{sudo apt-get install git-core, apache2, apache2-utils, libapache2-mod-php5, php5, php-pear, php5-xcache, php5-pgsql, postgresql, phppgadmin, pgadmin3}

\section{Configure Apache}

\subsection{Configure a virtual host}

\texttt{sudo nano /etc/apache2/sites-available/autoglosser}

Place the following in the file:

\begin{verbatim}
<VirtualHost *:80>
ServerName autoglosser
DocumentRoot /srv/www/autoglosser/public_html/
ErrorLog /srv/www/autoglosser/logs/error.log
CustomLog /srv/www/autoglosser/logs/access.log combined
</VirtualHost>
\end{verbatim}

\subsection{Tell the PC about the new virtual host}

\texttt{sudo nano /etc/hosts}

Add the following line:

\texttt{127.0.0.1	autoglosser}

\subsection{Enable the site and restart Apache}

\texttt{sudo a2ensite autoglosser}

\texttt{sudo /etc/init.d/apache2 restart}

\subsection{Give your normal user access to the \texttt{/srv} directory}

\texttt{sudo chown -R myuser.myuser /srv}

\subsection{Create a directory structure for the virtual host you set up earlier}

\texttt{mkdir -p /srv/www/autoglosser/public\_html}
\texttt{mkdir /srv/www/autoglosser/logs}

\subsection{Create a front-page for the virtual host}
\label{subsec:create-front-page}

\texttt{cd /srv/www/autoglosser/public\_html}

\texttt{nano index.html}

Enter the following:

\begin{verbatim}
<html>
<head>
<title>Autoglosser</title>
</head>
<body>
Front page for autoglosser virtual host.
</body>
</html>
\end{verbatim}

If you now enter \textbf{autoglosser} in the address bar of your browser you should see a page reading \textit{Front page for autoglosser virtual host}.

\section{Configure PHP}

Check the configuration of the \textbf{php.ini} file:

\texttt{sudo /etc/php5/apache2/php.ini}

Set the following parameters as given:

\begin{verbatim}
max_execution_time = 300
memory_limit = 64M
register_globals = Off
magic_quotes_gpc = Off
magic_quotes_runtime = Off
safe_mode = Off.
\end{verbatim}

Restart Apache:

\texttt{sudo /etc/init.d/apache2 restart}

\section{Configure PostgreSQL}

\subsection{Set PostgreSQL to use passwords}

\texttt{sudo nano /etc/postgresql/8.4/main/pg\_hba.conf}

Change the line:

\texttt{local   all	all	ident}

to:

\texttt{local   all	all	md5}

\subsection{Create a database user}
\label{subsec:create-db-user}

\texttt{sudo -i}

\texttt{su - postgresql}

\texttt{createuser -P mypguser}

Enter a password (twice), and enter \textbf{y} at the superuser question.

Enter \textbf{exit} twice to return to your normal (desktop) user.

You will have to use the username/password you have just entered to replace the default \textit{kevin/kevindbs} near the top of the \texttt{.php} scripts in the download.

\section{Download the autoglosser}

In a working directory of your choice, run:\\
\texttt{git clone http://thinkopen.co.uk/git/autoglosser}\\
The files will be downloaded into a \textit{autoglosser} folder in your working directory.

If you have chosen not to install Git, you can instead download the files by going to \textbf{http://thinkopen.co.uk/git/}, clicking on \textbf{autoglosser}, then on \textbf{tree}, and finally on \textbf{snapshot}.  This will download a tarball containing the files.  Uncompress this to create a \texttt{autoglosser} folder in your working directory.

Copy all the files in the \texttt{segmenter} folder to your new web directory at \texttt{\url{/srv/www/segmenter/public_html}}.  Delete the \textbf{index.html} file you created earlier at \ref{subsec:create-front-page}.

\section{Initialise the database}

\subsection{Create the database}

Go the the \texttt{dbs} folder and create a new database:

\texttt{createdb -U mypguser autoglosser}

using the PostgreSQL user you created earlier at \ref{subsec:create-db-user}.  Enter your PostgreSQL password when prompted.

\subsection{Import the tables}

[FIX: This section may not be necessary, since the autoglosser creates the tables on the fly.]

Log in to psql as your user:

\texttt{psql -U mypguser autoglosser}

At the \verb|autoglosser=#| prompt, enter:

\verb|\i table1.sql|

\verb|\i table2.sql|

Enter \verb|\q| to exit \textbf{psql}.

\subsection{Configure the database connection}

Open a text editor, and replace the username and password in the file \textbf{autoglosser/config.php} with the PostgreSQL username and password you created earlier at \ref{subsec:create-db-user}.

[FIX: All these files need to have \textbf{siarad} changed to \textbf{autoglosser}.]

Move the configuration details out of the web tree:

\texttt{sudo mv autoglosser /opt}

\section{Test access}

Open a web browser, and enter \textbf{autoglosser} on the location line.  You should see the front page of the autoglosser.

[FIX: Perhaps not required here - see above.]

If this does not work, contact me at \textbf{kevin@dotmon.com}.

\section{Ongoing database administration?}

To administer PostgreSQL, it is easiest to use a frontend.  You can use pgAdminIII\footnote{http://whatever}, a desktop interface, or (preferably) phpPgAdmin\footnote{http://whatever}, a browser-based interface.  Open a browser and enter \textit{localhost/phppgadmin} on the location bar.  Enter your PostgreSQL username and password, and you should see a list of databases in the left-hand panel - since this is a new install, there are only two: the postgres system database, and autoglosser, the one you have just created.  Click on autoglosser, and then on Schemas, and then on Tables.  There are no tables available yet in the autoglosser database, because you have not created any - the import process will create 4 tables for each file you import. 


\newpage


\begin{table}
\newcommand{\mc}[3]{\multicolumn{#1}{#2}{#3}}
\begin{tabularx}{\textwidth}{>{\hsize=0.5\hsize}X>{\hsize=1.5\hsize}X>{\hsize=0.5\hsize}X>{\hsize=1.5\hsize}X} 
\mc{2}{l}{\textbf{Tenses, moods, aspects}} & \mc{2}{l}{\textbf{Verbal extensions}} \\
\hline\noalign{\smallskip}
\textit{comp} & completive \textbf{-sha-, -isha-, -kwisha-} & \textit{assoc} & associative extension \textbf{\mbox{-an-}} \\ 
\textit{conc} & concessional \textbf{-nga-} & \textit{caus} & causative extension \textbf{-iz-, -ez-, -ish-, -esh-, -y-} \\ 
\textit{cond} & conditional \textbf{-nge-} & \textit{cont} & continuative extension \textbf{-t-} \\ 
\textit{cons} & consecutive \textbf{-ka-} & \textit{conv} & conversive extension \textbf{-u-, -o-} \\ 
\textit{curr} & current present \textbf{-na-} & \textit{inc} & inceptive extension \textbf{-p-} \\ 
\textit{fut} & future \textbf{-ta-} & \textit{pass} & passive extension \textbf{-w-} \\ 
\textit{hab} & habitual \textbf{hu-} & \textit{pos} & positional extension \textbf{-m-} \\ 
\textit{hypo} & hypothetical \textbf{-japo-} & \textit{prep} & prepositional extension \textbf{\mbox{-i-}, -e-} \\ 
\textit{imp} & imperative \textbf{-e} & \textit{stat} & stative extension \textbf{-ik-, \mbox{-ek-}} \\ 
\textit{gen} & general present \textbf{-a-} &  &  \\ 
\textit{part} & participial \textbf{-ki-} &  &  \\ 
\textit{past} & past \textbf{-li-} &  &  \\ 
\textit{perf} & perfective \textbf{-me-} &  &  \\ 
\textit{subj} & subjunctive \textbf{-e} &  &  \\ 
\textit{supp} & suppositional \textbf{-ngali-} & & 
\end{tabularx}
\caption{Tense and extension tags}
\label{table:verbtags}
\end{table}


\end{document}