list words that do not have gloss entries:
select welsh, count(welsh) from stammers4_cgwords where gloss is null group by welsh order by count desc
but this is not accurate, because manual glosses have been added - this doesn't mean that the items are in cylist

CREATE TABLE cylist_add (
    id integer NOT NULL,
    surface character varying(100),
    lemma character varying(100),
    pos character varying(20),
    gender character varying(20),
    num character varying(50),
    tense character varying(100),
    reg character varying(50),
    enlemma character varying(100),
    mutation character varying(20)
);
CREATE SEQUENCE cylist_add_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MAXVALUE
    NO MINVALUE
    CACHE 1;
ALTER SEQUENCE cylist_add_id_seq OWNED BY cylist.id;
ALTER TABLE cylist_add ALTER COLUMN id SET DEFAULT nextval('cylist_add_id_seq'::regclass);
ALTER TABLE ONLY cylist_add ADD CONSTRAINT cylist_add_pkey PRIMARY KEY (id);
CREATE INDEX cylist_add_surface ON cylist_add USING btree (surface);

egrep 'unk' outputs/stammers4_cg_applied.txt > unk.txt

Adding new entries:
cylist has 416862 entries
delete from cylist where id > 416862
insert into cylist (surface, lemma, pos, gender, num, tense, reg, enlemma, mutation) select surface, lemma, pos, gender, num, tense, reg, enlemma, mutation from cylist_add

fargain
broblem
bity
dop
drombone
fass
tagged as @0, but by definition these cannot be English, since they are mutated



Checking write_cgautogloss.php output
select w.utterance_id, w.location, w.mainlang, w.gloss, f.utterance_id as autoutt, f.location as autoloc, f.surface, f.lemma, f.tags from patagonia2_cgwords w, patagonia2_cgfinished f where w.utterance_id=f.utterance_id and w.location=f.location order by w.utterance_id, w.location


Select tablenames
select tablename from pg_tables where tablename !~'(pg_|sql_|_sp)' and tablename ~'_'




select * from patagonia1_cgfinished order by utterance, location



Generating cylist
[Run utils/cylist/pluralise.php on canonical.  This will fill the plurals table.]  NO!  Not required - the current version of canonical already has these plurals added.
Run utils/cylist/collect.php.  This will gather all entries from 4 separate tables (canonical, berfau, vplus, virreg) into eurfa_nmni.  The last section of the script writes the lemmas based either on the surface or (in the case of a plural surface) the sorp.
Run utils/cylist/gbl.php.  This will convert the gbl table into the more compact eurfa_gbl.
update eurfa_gbl set tense='pres' where tense='present';
update eurfa_gbl set tense='cond' where tense='conditional';
update eurfa_gbl set tense='dep' where tense='dependent';
update eurfa_gbl set tense='fut' where tense='future';
update eurfa_gbl set tense='imper' where tense='imperative';
update eurfa_gbl set tense='imperf' where tense='imperfect';
update eurfa_gbl set tense='pastsubj' where tense='past subjunctive';
update eurfa_gbl set tense='pluperf' where tense='pluperfect';
update eurfa_gbl set tense='subj' where tense='subjunctive';
update eurfa_gbl set number='1s' where number='1singular';
update eurfa_gbl set number='2s' where number='2singular';
update eurfa_gbl set number='3s' where number='3singular';
update eurfa_gbl set number='1p' where number='1plural';
update eurfa_gbl set number='1p' where number='1plural';
update eurfa_gbl set number='2p' where number='2plural';
update eurfa_gbl set number='3p' where number='3plural';
update eurfa_gbl set number='0' where number='impers';
update eurfa_gbl set number='0' where number='impersonal';
Run utils/cylist/combine.php to combine eurfa_gbl and eurfa_nmni into cylist, ready for use in the autoglosser.
Change yn to stative.
Set indexes on surface, lemma, enlemma, pos, gender, number and tense.

It is vitally important to set indexes on all relevant fields on the dictionary database table.  Without indexes, the cohort-writing for Patagonia1 on a dictionary that included mutated forms took 48s.  On a dictionary that did not include mutated forms, where the words were demutated and every demutation looked up on the fly, took 340s.  On the same dictionary, but with the demutated words only being looked up where they differed from the surface word, the time was 159s.  However, with indexes set on all the main columns, the total time was slashed to 8s. 











