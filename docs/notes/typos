select mainlang, count(mainlang) as freq, gloss, speaker from deuchar1_cgwords group by mainlang, gloss, speaker order by mainlang 

select * from deuchar1_cgutterances where mainlang ~ '<disabled'

select * from deuchar1_cgwords where utterance_id=1136

select * from lloyd1_typos where mainlang ~ '(t|d)ri' and gloss ~ 'NONFIN|PRES'

Develop different versions of fix_transcription to handle mainlang and gloss; move them down into the if-clauses for each.  This will enable other functions for different tiers if necessary.
deuchar1_cgwords
u 345: convert one or more spaces into one
l 1086: convert space+period into period: pron .1S -> pron.1S (knock-on effects?)
l 3068: now  be.3PL.PRES.NEG
l 3307: DETIM

Note that a mainlang item with NULL as the gloss has probably not been glossed in the text, because it is in English.

select mainlang, count(mainlang) as freq, tags, speaker from patagonia1_cgwords w, patagonia1_cgfinished f where w.utterance_id=f.utterance_id and w.location=f.location group by mainlang, tags, speaker order by mainlang 

not grouped by speaker:
select mainlang, count(mainlang) as freq, tags from patagonia1_cgwords w, patagonia1_cgfinished f where w.utterance_id=f.utterance_id and w.location=f.location group by mainlang, tags order by mainlang 



Tracking down typos
select mainlang, gloss, speaker, utterance_id, location from deuchar1_cgwords order by mainlang, gloss, speaker, utterance_id, location

*SER:   ond@1 oedd@1 hi@1 (y)n@1 oer@1 . %snd:"deuchar1"_614575_615272
%gls:   but be.3S.IMP pron .3SF PRT cold <=== space after pron
gives:
    ond but 
    oedd    be.3S.IMP   
    hi  pron    
    yn  .3SF    
    oer PRT 
    .   cold    

*SER:   &i well@0 <Bethel@0 oedd@1 o@1> [//] <(dy)dy@1 o@1 (ddi)m@1 yn@1> [//] (dy)dyn@1 nhw@1 (ddi)m@1 yn@1 galw@1 fo@1 (y)n@1 &e Bethel@0 xx . %snd:"deuchar1"_1560483_1563583
%gls:   well Bethel be.3S.IMP PRON.3SM be.3S.PRES.NEG PRON.3SM |PRON.3SM| NEG PRT be.3PL.PRES.NEG PRON.3PL NEG PRT call.NONFIN PRON.3SM PRT Bethel xx
Difficult to see, but there is a repetition of PRON.3SM, which puts the alignment off.

*SER:   so@0 <o'n@1 i@1> [//] fel@1 arfer@1 <mae@1 nhw@1 &d> [//] mae@1 (y)n@1 # dŵad@1 i@1 tŷ@1 ni@1 . %snd:"deuchar1"_1102548_1105625
%gls:   so be.1S.IMP PRON.1S like habit be.3PL.PRES || be.3S.PRES PRT come.NONFIN to house PRON.1PL
Missing PRON.3PL at || 

(586) *MYF: a@1 dw@1 i@1 sure@0 erbyn@1 meddwl@1 # mae@1 chwaer@1 hi@1 yn@1 gweithio@1 (y)n@1 Howells@0 . %snd:"deuchar1"_820406_825433
(587) and be.1S.PRES || sure by think.NONFIN be.3S.PRES sister PRON.3SF PRT work.NONFIN in Howells
Missing PRON.1S at || 

*MYF:   a@1 mae@1 o@1 a@1 (e)i@1 wraig@1 # mae@1 nhw@1 y@1 ddau@1 yn@1 eu@1 forties@2 . %snd:"deuchar1"_776186_780766
%gls:   and be.3S.PRES PRON.3SM and POSS.3SM wife be.3PL.PRES || DET two.M in POSS.3PL forties
Missing PRON.3PL at || 

(248) *MYF: yn@1 yn@1 car@0 mae@1 o@1 wedi@1 mynd@1 yeah@0 ? %snd:"deuchar1"_338073_339489
(249) in DET car be.3S.PRES PRON.3SM PRT.PAST go.NONFIN yeah
Second yn@1 should be y@1

*SER:   ryw@1 # bands@0 mae@1 (we)di@1 mynd@1 i@1 weld@1 ryw@1 groups@0 yeah@0 . %snd:"deuchar1"_410500_412932
%gls:   some band be.3S.PRES PRT.PAST go.NONFIN to see.NONFIN some groups yeah
Gloss should be bands instead of band

(371) *SER:   oh@0 <o'n@1 i@1> [/] o'n@1 i@1 (y)n@1 Llandudno@0 weekend@2 dwytha@1 . %snd:"deuchar1"_495273_497444
%gls:   IM be.1S.IMP pron||.1S be.1S.IMP PRON.1S in Llandudno weekend previous
Gap in pron.1S

*SER:   <fath@1 â@1 ddaru@1> [//] um@0 # mae@1 peth@1 (y)na@1 tydy@1 um@0 # oh@0 # &a Angharad@0 [//] um@0 # Elin_Angharad@0 yeah@0 ? %snd:"deuchar1"_1419001_1427227
%gls:   kind with happen.PAST IM be.3S.PRES thing there be.3S.PRES.NEG IM IM Angharad || Elin_Angharad yeah
Missing IM at ||

double spaces
xx xx 
both now covered in gloss import routines

Grouped query for final checking
select mainlang, count(mainlang) as freq, gloss from deuchar1_cgwords group by mainlang, gloss order by mainlang  # group all words and glosses - this shows up misalignments
select *  from deuchar1_cgwords where mainlang='dwytha' and gloss ='weekend'  # find the utterance_id of misaligned words
select * from deuchar1_cgwords where utterance_id=248 order by location  # view all the entries for that utterance - this allows mistakes to be spotted

select count(*) from deuchar1_cgwords where utterance_id in (137, 248, 286, 345, 371, 398, 453, 560, 586, 742, 773, 993, 1051, 1091)


Collecting unknown words
select lemma, count(lemma) from patagonia6_cgfinished where pos='m' group by lemma order by lemma (names)
select lemma, count(lemma) from patagonia6_cgfinished where pos='u' group by lemma order by lemma (unknown)

Log unknown words:
create table pat_unk as select langid, surface, count(surface) from herring1_cgwords where auto='unk' group by langid, surface order by langid, surface



Autoglosser todo

Use the same table structure for autoglossed and manually-glossed; otherwise, you need different queries for essentially the same thing.  For autoglossed, try to combine _cgwords and _cgfinished.

Check capitalised words (eg avenida) to see if they are in the dictionary without capitals - if so, use that entry; if not, tag the word as NAME.

Work on Eurfa:  (which probably needs to be reviewed anyway in light of planned additions)
1. Clarifiers are coming up in gloss - ensure they are in a separate column, and not concatenated
2. There are double entries for SM
3. Add mutated infinitives (eg pherswadio, feddwl)
4. Glosses containing spaces aren't coming up properly (eg ellith "be" instead of "be able")
5. Change numbers to "num"
6. Review lemma field.

Add examples of Siarad misalignment to the docs.

Improve Welsh CG.  Undisambiguated forms are the first step - they are running at around 10%.  The next step is incorrectly ambiguated forms - can only really be done by manual checking.  Would be a good idea to keep a note of these for the docs/paper.

Run queries on Siarad texts to catch typos that cause misalignments, and load onto git repo.  Suggest similar for Patagonia and Miami corpora.

Consider concatenation of numbers again, eg cant_a_chwe_deg.

Test (on new branch) benefits of splitting dictionary lookup from CG cohort generation.  At present, this is combined in write_cohorts.php - we read the _cgwords table, and look up each entry in the appropriate language dictionary (based on langid in _cgwords); then we write a text file to apply the CG to.  60% of words occur more than 10 times, so it would be possible to speed the dictionary process a lot by doing one lookup for each word and propagating that to all occurrences of that word in the table.  This is difficult if we want to maintain info about the different dictionary fields, and also because we would have multidimensionality - 2 or more cohort entries (adding something like links to extra tables would defeat the purpose of the thing).  One way forward is to select all the words in the _cgwords table into another table grouped by word (select mainlang, count(mainlang) from patagonia1_cgwords group by mainlang order by mainlang) and do the lookup on that.  Use the current code to populate two new fields - lemma and lookup/cohort, with the latter populated in a way that fits the CG requirements - or copy across the fields from the dictionary.  The latter will work fine for one-entry lookups, but if there are multi-entry lookups, what then?  Use an array in the fields?

Test carrying over the tags as separate fields instead of one concatenated tag in _cgfinished.  What about using the item's id number from the database, and using it to pull across the full list of tags, instead of concatenating direct from the CG stages?  The benefit would be that you don't have to segment the tags and assign them to fields.


Errors:

Warning: pg_query(): Query failed: ERROR:  value too long for type character varying(10) in /home/kevin/autoglosser/cgimport.php on line 99
means that there is a tab missing between the speaker and the rest of the line.  Strangely, it seems that once the first of these is fixed, the rest are OK???

Warning: pg_query(): Query failed: ERROR:  value too long for type character varying(10) in /home/kevin/autoglosser/cgimport.php on line 99
Can't insert the items
means there is no tab after the speaker ID




Miami/Patagonia

select surface, count(*), auto, langid from patagonia6_cgwords group by surface, auto, langid order by surface, auto, langid
select surface, count(*), auto, langid from patagonia2_cgwords where auto='unk' group by surface, auto, langid order by surface, auto, langid
select count(*) from patagonia2_cgwords
select * from patagonia6_cgwords where auto ~ '\\[or\\]'

